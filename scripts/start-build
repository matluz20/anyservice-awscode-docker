#!/bin/bash
set -e

if [ "${VERBOSE}" = true ]; then
  set -x
fi

OPTS=$@

# Check for required env vars
if [ -z "${CODEBUILD_S3_BUCKET}" ]; then
  echo "CODEBUILD_S3_BUCKET must be set"
  missing_vars=true
fi

if [ -z "${CODEBUILD_S3_ARCHIVE_KEY}" ]; then
  echo "CODEBUILD_S3_ARCHIVE_KEY must be set"
  missing_vars=true
fi

if [ "${missing_vars}" = "true" ]; then
  exit 1
fi

# Switching AWS principal
if [ -n "${AWS_ASSUME_ROLE}" ]; then
  AWS_ASSUME_ROLE_ARN=${AWS_ASSUME_ROLE}
  unset AWS_ASSUME_ROLE
  # set defaut aws assume-role session duration to 1 hour if not set
  if [ -z "${AWS_ASSUME_ROLE_DURATION}" ]; then
    AWS_ASSUME_ROLE_DURATION=3600
  fi
  . aws_assume_role "${AWS_ASSUME_ROLE_ARN}" --duration-seconds ${AWS_ASSUME_ROLE_DURATION}
fi

# Detect CI environment: either BITBUCKET or GITLAB_CI
if [ -n "${BITBUCKET_COMMIT}" ]; then
  # BITBUCKET doc: https://confluence.atlassian.com/bitbucket/environment-variables-794502608.html
  ci_env_pattern="BITBUCKET_"
  codebuild_result_file="${BITBUCKET_REPO_OWNER}.${BITBUCKET_REPO_SLUG}.${BITBUCKET_COMMIT}.json";

  echo "Detected BitBucket environment"
elif [ -n "${GITLAB_CI}" ]; then
  # GITLAB doc: https://docs.gitlab.com/ce/ci/variables/README.html
  ci_env_pattern="CI_|GITLAB_"
  codebuild_result_file="${CI_PROJECT_NAMESPACE}.${CI_COMMIT_REF_SLUG}.${CI_COMMIT_SHA}.json";

  echo "Detected GitLab environment"
fi

# Add additionals environment variables patterns to pass vars to codebuild when matching a given prefix
if [ -n "${CI_ENV_PATTERN}" ]; then
  ci_env_pattern="${ci_env_pattern}|${CI_ENV_PATTERN}"
fi

# Wait for Codebuild by default
WAIT_FOR_CODEBUILD=${WAIT_FOR_CODEBUILD:-true}

# Build source code archive for selected commit using option -y to preserve symlinks
CODEBUILD_CHROOT=${CODEBUILD_CHROOT:-.}
PWD=`pwd`
cd ${CODEBUILD_CHROOT}
zip -r -y -q ${PWD}/code.zip .
cd ${PWD}

s3_put_archive() {
  aws s3api put-object \
    --body ./code.zip \
    --bucket ${CODEBUILD_S3_BUCKET} \
    --key ${CODEBUILD_S3_ARCHIVE_KEY} \
    --output text --query 'VersionId'
};

## Put source code archive on specified S3 Bucket/Key and extract object version
echo
echo "-> Uploading code (${CODEBUILD_CHROOT}) to S3 location: s3://${CODEBUILD_S3_BUCKET}/${CODEBUILD_S3_ARCHIVE_KEY}"

version_id=$(s3_put_archive)

echo "S3 Object version for uploaded code is: ${version_id}"


# helper to format env vars containing the ci_env_pattern (BITBUCKET_ or CI_|GITLAB_CI_) in a line-separated list `{"name":"NAME","value":"VALUE"}` elements
ci_env_json() {
  env \
    | grep -E ${ci_env_pattern} \
    | jq -Rc 'split("\n") | map(split("=") | { "name": .[0], "value": .[1] }) | .[]'
};


## Start build
start_build() {
  ## build a codebuild "cli-input-json" object out of the CI env vars, so they can be passed to codebuild runner
  # format:
  # {
  #   "environmentVariablesOverride": [
  #     {"name":"foo","value":"bar"},
  #     {"name":"bar","value":"baz"},
  #      ...
  #   ]
  # }
  echo $(ci_env_json) | jq -s -c '{environmentVariablesOverride:.}' > /tmp/_cli_input.json;

  # User provided a a codebuild "cli-input-json" file: merge it with environment variables gathered in _cli_input.json file
  # The spec of the user provided cli-input-file can be found here: https://docs.aws.amazon.com/codebuild/latest/APIReference/API_StartBuild.html
  if [ -n "${CODEBUILD_START_JSON_FILE}" ]; then
    jq -s -c '[.[] | to_entries] | flatten | reduce (.[]) as $dot ({}; (if ($dot.value|type == "array") then .[$dot.key] += $dot.value else .[$dot.key] = $dot.value end))' /tmp/_cli_input.json ${CODEBUILD_START_JSON_FILE} > /tmp/_cli_input.json;
  fi

  # make sure the cli input file does not have duplicate env var entries
  jq -s -c '.[] | .environmentVariablesOverride |= unique' /tmp/_cli_input.json > /tmp/cli_input.json;

  # helper to conditionally pass the `--project-name` option to codebuild start-build command
  local project_name_arg="--project-name ${CODEBUILD_PROJECT_NAME}";
  if [ -z ${CODEBUILD_PROJECT_NAME} ]; then
    project_name_arg="";
  fi

  aws codebuild start-build ${project_name_arg} \
    --source-version ${version_id} \
    --cli-input-json file:///tmp/cli_input.json \
    --output text \
    --query 'build.id' \
    ${OPTS}
};

# Start build and record the build id
start_build_id=$(start_build);
echo "-> Started build: ${start_build_id}";
echo "Build details are available at the following url:"
echo "https://${AWS_DEFAULT_REGION}.console.aws.amazon.com/codebuild/home?region=${AWS_DEFAULT_REGION}#/builds/${start_build_id}/view/new"
## Wait for build result (conditional)
if [ ${WAIT_FOR_CODEBUILD} = "true" ]; then

  fetch_logs() {
    if [ -z "${build_cwlogs_stream}" ] || [ "${build_cwlogs_stream}" = "null" ]; then
      build_logs=`aws codebuild batch-get-builds --ids ${start_build_id} --query 'builds[0].logs'`
      build_cwlogs_group=`echo ${build_logs} | jq -c -r '.groupName'`;
      build_cwlogs_stream=`echo ${build_logs} | jq -c -r '.streamName'`;

      if [ "${build_cwlogs_stream}" != "null" ]; then
        echo "Cloudwatch logs are available at the following url:"
        echo "https://${AWS_DEFAULT_REGION}.console.aws.amazon.com/cloudwatch/home?region=${AWS_DEFAULT_REGION}#logEventViewer:group=${build_cwlogs_group};stream=${build_cwlogs_stream}"
      else
        echo "Waiting for Cloudwatch Logs info"
        sleep 5
        fetch_logs
      fi
    fi

    # get log events
    if [ "${has_events}" != "true" ]; then
      # always start from the beginning when we didn't fetch any log events yet
      log_events=`aws logs get-log-events --log-group-name ${build_cwlogs_group} --log-stream-name ${build_cwlogs_stream} --start-from-head`
    else
      # otherwise, resume from where we left
      log_events=`aws logs get-log-events --log-group-name ${build_cwlogs_group} --log-stream-name ${build_cwlogs_stream} --start-from-head --next-token ${nextForwardToken}`
    fi

    # extract log events
    events=`echo ${log_events} | jq -c -r '.events[]'`
    
    if [ "${has_events}" = "true" ] || [ "${events}" != "" ]; then
      if [ "${has_events}" != "true" ]; then
          echo "-> Log events follow:"
          echo "------------------------------------------"
      fi
      has_events=true
    else
      echo "Waiting for logs"
      sleep 10
      fetch_logs
    fi

    # keep previous nextForwardToken value
    previousNextForwardToken=${nextForwardToken}
    # extract token for logs pagination
    nextForwardToken=`echo ${log_events} | jq -c -r '.nextForwardToken'`;
    
    # get-log-events may or may not return the same token when reaching the end of the stream, so we also check whether there are new events in the response and keep iterating from the same token until there are new log events
    if [ "$nextForwardToken" = "$previousNextForwardToken" ] || [ "$events" = "" ]; then
      nextForwardToken=$previousNextForwardToken
      return 
    fi

    # decode and print log events (we use python to iterate over log events as bash loops are too slow)
    echo ${log_events} | jq -c -r '.events' > events
    python3 /usr/local/bin/print_events.py events

    # we have reached the end of the stream but there might be remaining log events, so we self invoke right away
    fetch_logs
  }

  # Wait until build is complete and fetch logs
  until [ "$(aws codebuild batch-get-builds --ids ${start_build_id} --output text --query 'builds[0].buildComplete')" = "True" ];
  do
    fetch_logs;
    # wait 10s before checking build status again
    sleep 10;
  done

  # fetch last logs
  fetch_logs

  ## Build has completed, it is either in state SUCCEEDED or in faulty state: FAILED, FAULT, STOPPED, TIMED_OUT

  # Get build result
  # output spec: https://docs.aws.amazon.com/cli/latest/reference/codebuild/batch-get-builds.html#output
  build_result=$(aws codebuild batch-get-builds --ids "${start_build_id}" --query "builds[0]");

  # Save build result to S3 bucket (conditional)
  if [ -n "$CODEBUILD_S3_RESULT_PATH" ]; then
    echo "Saving build result to S3 location: s3://${CODEBUILD_S3_BUCKET}/${CODEBUILD_S3_RESULT_PATH}/${codebuild_result_file}"
    echo ${build_result} | jq . > _build_result;

    s3_put_result() {
      aws s3api put-object \
        --body _build_result \
        --bucket ${CODEBUILD_S3_BUCKET} \
        --key "${CODEBUILD_S3_RESULT_PATH}/${codebuild_result_file}"
    }

    quiet=$(s3_put_result)
  fi

  # Artifacts
  artifacts=`echo ${build_result} | jq -c -r '.artifacts'`;
  artifacts_location=`echo ${artifacts} | jq -c -r '.location'`;
  
  if [ "${artifacts_location}" != "" ]; then
    echo "-> Artifacts were generated for this build:"
    echo "${artifacts}" | jq .
    
    ## Extract artifacts S3 bucket and key
    # Artifacts_location format : "arn:aws:s3:::company-dev-s3-cicd-xxx/codebuild/myproject/artifacts/f4cc70cc-0f38-4cd3-b839-5464bf6b8ed5/codebuild_artifacts.zip"
    artifacts_s3=`echo ${artifacts_location} | awk -F: '{print $6}'`;
    artifacts_s3_bucket=`echo ${artifacts_s3} | cut -d '/' -f 1`;
    artifacts_s3_key=`echo ${artifacts_s3} | cut -d '/' -f 2-`;

    GITLAB_ARTIFACTS_DIR="${GITLAB_ARTIFACTS_DIR:-.codebuild_artifacts}";
    mkdir -p "${GITLAB_ARTIFACTS_DIR}";
    cd "${GITLAB_ARTIFACTS_DIR}";

    ## Fetch artifact files in current dir
    CODEBUILD_ARTIFACTS_PACKAGING="${CODEBUILD_ARTIFACTS_PACKAGING:-ZIP}";

    if [ "${CODEBUILD_ARTIFACTS_PACKAGING}" = "NONE" ]; then
      aws s3 sync s3://${artifacts_s3_bucket}/${artifacts_s3_key}/ .;
    elif [ "${CODEBUILD_ARTIFACTS_PACKAGING}" = "ZIP" ] ; then
      if `aws s3 cp --quiet s3://${artifacts_s3_bucket}/${artifacts_s3_key} .` ; then
        artifacts_name=`basename $artifacts_s3_key`;
        unzip $artifacts_name;
        rm -f $artifacts_name;
        echo "Fetched artifacts from ${artifacts_s3_bucket}/${artifacts_s3_key}";
        ls
      else
        echo "Failed fetching artifacts from ${artifacts_s3_bucket}/${artifacts_s3_key}";
      fi
    else
      echo "Unsupported CODEBUILD_ARTIFACTS_PACKAGING value";
    fi

  fi

  # Extract build status from job details
  codebuild_status=`echo ${build_result} | jq -c -r '.buildStatus'`;

  # Build succeeded
  if [ ${codebuild_status} = "SUCCEEDED" ]; then
    echo "-> Build ${start_build_id} completed successfully!";

  # Build failed
  else
    echo "-> Build ${start_build_id} failed!";
    echo "Build failure reason: ${codebuild_status}";
    exit 1;
  fi

fi
